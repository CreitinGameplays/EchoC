-- This script demonstrates a complex asynchronous workflow in EchoC --
-- It includes concurrent task execution, error handling, and data processing. --

load: weaver:

--  Synchronous Helper Functions --

funct: generate_initial_data(count):
    -- Generates an array of dictionaries for initial processing. --
    show("SYNC: Generating %{count} initial data items."):
    let: data_list = []:
    loop: for i from 1 to count:
        let: new_item = {
            "id": i,
            "value": "item_%{i}",
            "status": "pending"
        }:
        data_list.append(new_item):
    return: data_list:

funct: format_report(processed_items, errors):
    -- Formats a final report string from processed items and errors. --
    show("SYNC: Formatting report. Processed: %{processed_items.len}, Errors: %{errors.len}"):
    
    let: report_lines = ["--- Processing Report ---"]:
    report_lines.append("Successfully processed %{processed_items.len} items:"):
    
    loop: for item in processed_items:
        -- Use a helper variable to find the ID, similar to Python's .get() logic --
        let: item_id = null:
        try:
            let: item_id = item["id"]:
        catch:
            try:
                let: item_id = item["original_id"]:
            catch:
                let: item_id = "N/A":
        
        let: result = null:
        try:
            let: result = item["result"]:
        catch:
            try:
                let: result = item["detail"]:
            catch:
                let: result = "N/A":
        
        report_lines.append("  - ID: %{item_id}, Result: %{result}"):

    if: errors.len > 0:
        report_lines.append("Encountered %{errors.len} errors:"):
        loop: for err in errors:
            let: err_id = null:
            try:
                let: err_id = err["id"]:
            catch:
                let: err_id = "N/A":
            
            let: err_msg = null:
            try:
                let: err_msg = err["error_message"]:
            catch:
                let: err_msg = "Unknown error":

            report_lines.append("  - Item ID: %{err_id}, Error: %{err_msg}"):
    else:
        report_lines.append("No errors encountered."):
    
    report_lines.append("--- End of Report ---"):

    -- Join the lines into a single string --
    let: final_report_str = "":
    let: first = true:
    loop: for line in report_lines:
        if: first:
            let: final_report_str = line:
            let: first = false:
        else:
            let: final_report_str = final_report_str + "\n" + line:
    return: final_report_str:

-- Asynchronous Helper Functions --

async funct: simulate_io_delay(operation_name, duration_ms):
    -- Simulates a non-blocking I/O operation like a network call or disk read. --
    show("ASYNC: Starting IO delay for '%{operation_name}' (%{duration_ms}ms)..."):
    await weaver.rest(duration_ms):
    show("ASYNC: ...Finished IO delay for '%{operation_name}' (%{duration_ms}ms)."):
    return: "%{operation_name} completed after %{duration_ms}ms":

async funct: fetch_resource_data(resource_id, fail_on_id):
    -- Simulates fetching a resource, with a possibility of a simulated failure. --
    show("ASYNC: Attempting to fetch resource '%{resource_id}'..."):
    await simulate_io_delay("fetch_resource_%{resource_id}", 150):
    
    if: resource_id == fail_on_id:
        show("ASYNC: ...Fetch FAILED for resource '%{resource_id}' (simulated error)."):
        raise: "Simulated network error for resource %{resource_id}":
    
    let: data_payload = {
        "id": resource_id,
        "content": "Content for resource %{resource_id}",
        "timestamp": "2023-10-27T10:00:00Z",
        "metadata": ["tag1", "tag2", ("even_tag" if resource_id.len % 2 == 0 else "odd_tag")]
    }:
    show("ASYNC: ...Successfully fetched resource '%{resource_id}'."):
    return: data_payload:

async funct: process_data_item(item_data, processing_complexity):
    -- Simulates a CPU-bound or I/O-bound task for processing a single data item. --
    show("ASYNC: Processing item ID '%{item_data["id"]}' with complexity %{processing_complexity}..."):
    let: delay_ms = 50 + (processing_complexity * 2):
    await simulate_io_delay("process_item_%{item_data["id"]}", delay_ms):

    let: result_dict = {"original_id": item_data["id"], "status": "processed"}:
    
    -- Simulate a processing failure for some items --
    if: item_data["id"] % 4 == 0:
        show("ASYNC: ...Processing FAILED for item ID '%{item_data["id"]}' (simulated internal error)."):
        let: result_dict["status"] = "error":
        let: result_dict["error_detail"] = "Simulated processing failure.":
    elif: processing_complexity > 2:
        let: result_dict["detail"] = "Complex processing successful. Value: %{item_data["value"] * 2}":
        let: result_dict["value_length"] = item_data["value"].len:
    else:
        let: result_dict["detail"] = "Simple processing successful.":
        let: result_dict["value_length"] = item_data["value"].len + 5:

    show("ASYNC: ...Finished processing item ID '%{item_data["id"]}'. Status: %{result_dict["status"]}"):
    return: result_dict:

-- Main Asynchronous Orchestrator --

async funct: main_async_workflow():
    -- The main orchestrator that runs the entire asynchronous workflow. --
    show("--- ASYNC WORKFLOW STARTED ---"):

    let: initial_items = generate_initial_data(5):
    show("Initial items: %{initial_items}"):

    let: setup_message = await simulate_io_delay("system_setup", 1000):
    show(setup_message):

    let: processed_results = []:
    let: error_log = []:
    let: iteration_count = 0:

    show("--- Starting main processing loop ---"):
    loop: while iteration_count < initial_items.len:
        let: current_item = initial_items[iteration_count]:
        show("LOOP Iteration %{iteration_count + 1}: Processing item ID '%{current_item["id"]}'"):

        try:
            -- Every 3rd iteration, try fetching extra resources concurrently --
            if: iteration_count % 3 == 0:
                show("LOOP: Special handling for iteration %{iteration_count + 1} - fetching extra resources."):
                -- Create tasks to run concurrently --
                let: resource_task1 = fetch_resource_data("extra_A_%{current_item["id"]}", "extra_A_3"):
                let: resource_task2 = fetch_resource_data("extra_B_%{current_item["id"]}", "non_existent_fail_id"):
                
                show("LOOP: Gathering extra resources..."):
                let: extra_resources = await weaver.gather([resource_task1, resource_task2], return_exceptions=true):
                show("debug 2: %{extra_resources}"):
                show("LOOP: Extra resources gathered. Count: %{extra_resources.len}"):
                
                -- Process gathered resources --
                let: i = 0:
                loop: for res_data in extra_resources:
                    show("small debug: %{res_data}"):
                    if: type(res_data) == "string":
                        show("LOOP: Gathered resource %{i + 1} had an error: %{res_data}"):
                        error_log.append({"id": "extra_resource_%{i}", "error_message": res_data}):
                    elif: type(res_data) == "dictionary":
                        show("LOOP: Gathered resource %{i + 1} data: %{res_data["content"]}"):
                        let: current_item["extra_info_%{i}"] = res_data["metadata"]:
                    else:
                        show("LOOP: Gathered resource %{i + 1} has unexpected type: %{type(res_data)}"):
                    let: i = i + 1:
                
                let: item_process_complexity = 3:
                let: processing_result = await process_data_item(current_item, item_process_complexity):
                if: processing_result["status"] == "processed":
                    processed_results.append(processing_result):
                else:
                    error_log.append({"id": current_item["id"], "error_message": processing_result["error_detail"]}):

            -- Even iterations (but not divisible by 3) --
            elif: iteration_count % 2 == 0:
                show("LOOP: Standard processing for item ID '%{current_item["id"]}'"):
                let: fetched_single_resource = await fetch_resource_data("main_%{current_item["id"]}", "main_4"):
                show("LOOP: Main resource for item ID '%{current_item["id"]}': %{fetched_single_resource["content"]}"):
                let: current_item['main_content_length'] = fetched_single_resource['content'].len:
                
                let: item_process_complexity = 1:
                let: processing_result = await process_data_item(current_item, item_process_complexity):
                if: processing_result["status"] == "processed":
                    processed_results.append(processing_result):
                else:
                    error_log.append({"id": current_item['id'], "error_message": processing_result["error_detail"]}):
            
            -- Odd iterations (but not divisible by 3) --
            else:
                show("LOOP: Quick processing for item ID '%{current_item["id"]}'"):
                await simulate_io_delay("quick_op_item_%{current_item["id"]}", 30):
                let: current_item['status'] = "quick_processed":
                let: current_item['quick_detail'] = "Performed quick operation. Value: %{current_item["value"]}_quick":
                processed_results.append(current_item):
        
        catch as e:
            show("LOOP: EXCEPTION CAUGHT for item ID '%{current_item["id"]}': %{e}"):
            error_log.append({"id": current_item['id'], "error_message": e}):
        finally:
            show("LOOP: Finally block for item ID '%{current_item["id"]}' in iteration %{iteration_count + 1}."):

        let: iteration_count = iteration_count + 1:
        if: iteration_count == 3:  -- Test break --
            show("LOOP: Reached iteration 3, breaking loop for demonstration."):
            break:
    
    show("--- Main processing loop finished ---"):
    show("--- Starting final batch of concurrent tasks ---"):
    
    let: final_task_ids = ["final_alpha", "final_beta", "final_gamma_FAIL", "final_delta"]:
    let: final_tasks_to_run = []:
    loop: for task_id_str in final_task_ids:
        let: fail_id_for_fetch = "final_gamma_FAIL" if task_id_str == "final_gamma_FAIL" else "no_fail_expected":
        let: task_coro = fetch_resource_data(task_id_str, fail_id_for_fetch):
        final_tasks_to_run.append(task_coro):
    
    show("Final tasks created. Gathering all %{final_tasks_to_run.len} final tasks..."):
    let: final_gathered_results = await weaver.gather(final_tasks_to_run, return_exceptions=true):
    show("--- Final batch tasks gathered ---"):

    let: i = 0:
    loop: for res in final_gathered_results:
        if: type(res) == "string":
            show("Final Task %{i} Result (Error): %{res}"):
            error_log.append({"id": final_task_ids[i], "error_message": res}):
        elif: type(res) == "dictionary":
            show("Final Task %{i} Result (Success for '%{res["id"]}'): %{slice(res["content"], 0, 20)}..."):
            processed_results.append({"id": res["id"], "result": "Final task success", "content_preview": slice(res["content"], 0, 10)}):
        let: i = i + 1:

    let: final_report = format_report(processed_results, error_log):
    show(final_report):

    show("--- ASYNC WORKFLOW FINISHED ---"):
    return: "Workflow completed. Processed: %{processed_results.len}, Errors: %{error_log.len}":

-- Run the main async workflow --
show("--- async_workflow.echoc starting ---"):
let: final_status = weaver.weave(main_async_workflow()):
show(final_status):
show("--- async_workflow.echoc finished ---"):